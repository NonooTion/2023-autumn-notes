# 机器学习基础

## 第一章 绪论

### 1.1 引言

**机器学习**

研究如何通过计算的手段，利用经验来改善系统自身性能的一门学科

- 经验：通常以数据的形式存在
- 研究的主要内容：关于在计算机上从数据中产生模型(model)的算法，即**学习算法**(learning algorithm)
  - 学习算法可以基于提供的经验数据产生模型
  - 当面对新的情况时，模型会给我们提供响应的判断

> 在机器学习基础(周志华)书中，模型泛指从数据中学得的结果
>
> 在有的文献中，模型值全局性结果，而用模式指局部性结果



### 1.2 基础术语

**要进行机器学习，数据是前提条件**

以一批西瓜有关的数据为例：

(色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂:稍蜷;敲声=沉 闷)， (色泽=浅自;根蒂 硬挺;敲声=清脆)

每对括号间是一条**记录**，"=" 意思是 "取值为"

这组记录的集合称为一个"**数据集**"(data set)

每条记录时关于一个事件或对象的描述，称为一个"**示例**"(instance)或"**样本**"(sample)

反映事件或对象在某方面的表现或性质的事项，称为"**属性**"(attribute)或"**特征**"(feature),属性上的取值叫做"**属性值**"(attribute value)

属性张成的空间称为"**属性空间**"(attribute space),"**样本空间**(sample space)"或"输入空间"

一个示例称为一个"**特征向量**"(feature vector)



一般地，令
$$
D={x_1,x_2,...,x_m}
$$
表示m个示例地数据集，每个示例由d个属性描述,则每个实例
$$
x_i=(x_{i1},x_{i2},...,x_{id})
$$
是d维样本空间$X$中地一个向量，其中$x_{ij}$是$x_i$在第j个属性上的取值,d称为样本的维数



从数据中学习模型的过程称为"**学习**"(learning)或"**训练**"(training),这个过程通过执行某个学习算法来完成，其中每个样本称为一个"**训练样本**"(training sample),训练样本组成的集合称为"**训练集**"(training set)

学得模型对应了关于数据的某种潜在规律，因此也成为"**假设**"(hypothesis)，这种潜在规律自身，称为**真相**或**真实**(ground-truth)，学习过程就是为了找出或逼近真相，模型有时也成为"**学习器**"(learner)



学得一个能够帮助我们进行判断的模型，仅有前面示例中的示例数据是不够的，要建立一个关于预测的模型，我们还需要训练样本的"结果"信息

例如: ((色泽:青绿;根蒂二蜷缩; 敲声=浊响)，好瓜)

关于示例结果的信息，例如"好瓜"，称为"**标记**"(label)

拥有了标记的示例，则称为"**样例**"(example)

一般，使用$(x_i,y_i)$表示第i个阳历，其中$y_i$是示例$x_i$的标记，所有标记的集合称为"**标记空间**"(label space)或"输出空间"



**学习任务的分类**

欲预测的是离散值，此类学习任务称为"**分类**"(classification)

若欲预测的是连续值，如西瓜成熟度,此类学习任务称为"**回归**"(regression)

只涉及两个类别的"**二分类**"(binary classification)任务，通常称其中一个类为正类(positive class)，一个为反类(negative class)

涉及多个类别时，则称为"**多分类**"(multi-class classification)任务

预测任务希望通过训练集进行学习，建立一个从输入空间到输出空间的映射

学得模型后，使用其进行预测的过程称为"**测试**"(testing),被测试的样本叫做测试样本



我们还可以对记录做"**聚类**"(clustering)，即将训练集中的记录分成若干组，每个组称为一个簇，这样的学习过程有助于我们了解数据内在的规律，能为更深入地分析数据建立基础



根据训练数据是否有标记信息，学习任务可分为两大类：

1. 监督学习(包括分类和回归)
2. 无监督学习(包括聚类)



> 机器学习地目标是使学得模型能够很好地适用于"新样本"，而非仅仅在训练样本上工作的很好
>
> 一般而言，训练样本越多，我们得到的关于D（样本服从的分布）的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型.



### 1.3 假设空间

"从样例中学习"是一个归纳的过程，亦称"**归纳学习**"(inductive learning)

归纳学习有狭义和广义之分，广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习要求从训练数据中学得概念，亦称"**概念学习**"

概念学习中最基本的是布尔概念学习，即对"是" "不是"这样的可以表示为0/1布尔值的目标概念的学习

学习过程看作一个在所有**假设**(hypothesis)组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设，即能够将训练集中的示例判断正确的假设

可以有多种策略对这个假设空间进行搜索，如自顶向下，从一般到特殊，或自底向上，从特殊到一般，搜索过程中不断删除与正例不一致的假设，或和反例一致的加色，最终可以获得与训练集一致的假设，就是学得的结果

可能存在多个假设与训练集一致，即存在着一个与训练集一致的"假设集合"，我们称之为"**版本空间**"(version space)



以一个实际的例子为例，通过一个西瓜的数据集，进行布尔学习，进而获得版本空间

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E6%95%B0%E6%8D%AE%E9%9B%861-1.png)

假设色泽有3种取值，根蒂3种，敲声3种，我们面临的假设空间大小为 4 x 4 x 4+1=65种

要考虑极端情况，所有色泽，根蒂，或敲声的西瓜都是好瓜，或世界上根本没有好瓜(+1)

根据上面的假设，我们可以获得西瓜问题的假设空间 

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E9%97%AE%E9%A2%98%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4.png)

根据数据集，删除与正例不一致或与反例一致的假设，可以得到版本空间

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E9%97%AE%E9%A2%98%E7%89%88%E6%9C%AC%E7%A9%BA%E9%97%B4.png)



### 1.4 归纳偏好

通过学习得到的模型对一个假设空间中的一个假设

对于上例，我们得到了三个与训练集一致的假设，但它们对应的模型在面临新样本时，却产生不同的输出

> (色泽=青绿，根蒂=蜷缩;敲声=沉闷) 
> 如果我们采用的是 好瓜$\leftrightarrow$(色泽=\* )$\and$(根蒂=蜷缩)$\and$(敲声=\*)"，那么将会把新瓜判断为好瓜
>
> 若用其他两个假设，则会判断为不是好瓜



无法断言上述三个假设中哪一个更好

对于一个具体的学习算法而言，它必须要产生一个模型。这时，学习算法本身的偏好就起到关键的作用

> 例如：我们的算法喜欢更特殊的模型，或更一般的模型



机器学习算法在学习过程中对某种类型假设的偏好，称为"**归纳偏好**"(inductive bias)，简称为"偏好"

> 任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看 似在训练集上"等效"的假设所迷惑，而无法产生确定的学习结果.



**奥卡姆剃刀**

一种常用的、自然科学研究中最基本的原则

若有多个假设与观察一致，则选最简单的那个



**"没有免费午餐"定理**

无论学习算法多聪明或笨拙，它们的期望性能相同



证明：

假设样本空间$\chi$和假设空间$\Eta$都是离散的.令$P(h|\Chi,\mathcal L_a)$表示算法$\mathcal L_a$基于训练数据X产生假设h的概率，再令f代表我们希望学习的真实目标函数，$\mathcal L_a$的训练集外误差，即训练集之外的所有样本上的误差为
$$
E_{ote}(\mathcal L_a|\Chi,f)=\sum_h \sum_{x\in\chi-\Chi}P(x) Ⅱ(h(x)\ne f(x))P(h|\Chi,\mathcal L_a) \\
$$
考虑二分类问题，且真实目标函数可以是任何函数$\chi \to \{0,1\}$，函数空间为$\{0,1\}^{|\chi|}$，对所有可能的f按均匀分布对误差求和，有
$$
\sum_{f}E_{ote}(\mathcal L_a|\Chi,f)=\sum_f\sum_h \sum_{x\in\chi-\Chi}P(x) Ⅱ(h(x)\ne f(x))P(h|\Chi,\mathcal L_a)
$$


$$
\sum_{f}E_{ote}(\mathcal L_a|\Chi,f)=\sum_{x\in\chi-\Chi}P(x)\sum_hP(h|\Chi,\mathcal L_a)\sum_fⅡ(h(x)\ne f(x))
$$

所有可能的真实目标函数f有$2^{\chi}$种，通过算法学习出来的模型h(X)对x的预测值有1/2的概率与f(x)相同，即
$$
\sum_fⅡ(h(x)\ne f(x))=\frac{1}{2}2^{|\chi|}
$$

$$
E_{ote}(\mathcal L_a|\Chi,f)=\sum_{x\in\chi-\Chi}P(x)\sum_hP(h|\Chi,\mathcal L_a)\frac{1}{2}2^{|\chi|}
$$

易知
$$
\sum_hP(h|\Chi,\mathcal L_a)=\frac{1}{2^{|\chi|}}
$$
则
$$
\sum_{f}E_{ote}(\mathcal L_a|\Chi,f)=2^{|\chi|-1} \sum_{x\in\chi-\Chi}P(x)
$$


脱离具体问题，空 泛地谈论"什么学习算法更好"毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题;在 某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法 自身的归纳偏好与问题是否相配，往往会起到决定性的作用.



## 第二章 模型评估与选择

### 2.1 经验误差与过拟合

学习器的实际预测输出和样本的真实输出之间的差异称为**"误差"**(error)

学习器在训练集上的误差称为"**训练误差**"(training error)或"**经验误差**"(empirical error)

在新样本上的误差称为"**泛化误差**"(generalization error)

> 我们显然希望得到泛化误差较小的学习器

当学习器把训练样本学得"太好"的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种情况在机器学习种称为"**过拟合**"(overfitting)

与之相对应的，对训练样本的一般性质尚未学好，叫做"**欠拟合**"(underfitting)

>导致过拟合的因素有很多，比如学习能力过于强大..
>
>而欠拟合一般是因为学习能力地下而造成的
>
>一般来说，欠拟合比较容易客服，在决策树中扩展分支，在神经网络学习种增加训练轮数即可
>
>过拟合一般比较麻烦，过拟合问题是机器学习面临的关键障碍，各类算法必然带有一些针对过拟合的措施，过拟合无法避免，只能缓解或减小其风险

在现实任务中，我们往往有多种学习算法可以选择，对于一种算法，当使用不同参数配置时，也会产生不同的模型，我们应当选择泛化误差最小的模型使用，这个问题叫做"**模型选择**"(model selection)

### 2.2 评估方法

我们可以通过实验测试来对学习器的泛化误差进行评估进而做出选择

这需要一个**测试集**(testing set)来测试学习器对新样本的判别能力，然后以测试机上的"测试误差"作为泛化误差的近似

> 测试样本通常从样本真实分布中独立同分布获得
>
> 测试集应该尽可能与训练集互斥，即测试样本尽量不再训练集中出现、未在训练集中使用过

我们通常只有一个包含m个样例的数据集D=$\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$，既要训练，又要测试，如何做？

对D进行适当的处理，从中产出训练集S和测试集T

下面介绍几种常见的作法

#### 2.2.1 留出法

直接将数据D划分为两个互斥的集合，其中一个集合用作训练集S，另一个作为测试集T，即D=$S∪T$,$S∩T=\empty$

在S上训练出模型后，使用T来评估其测试误差，作为对泛化误差的估计

**注意**:

1. 留出法的训练，测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响

> 例如：在二分类任务中，D有1000个样本，将D划分为S包含700个样本，T包含300个样本，若D包含500个正例，500个反例，则S中包含350个正例，350个反例，T中包含150个正例，150个反例

2. 即便在给定测试/训练集的样本比例后，仍然存在多种划分方式对初始数据集进行分割

> 因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分，重复进行实验评估后取平均值作为留出法的评估结果

**留出法的缺点**

若令训练集S包含绝大多数样本，则训练出来的模型可能接近使用D训练出的模型，但由于T比较小，评估结果可能不够稳定准确

若令测试集T多包含一些样本，则测试集S与D差别更大了，被评估的模型与用D训练出的模型相比可能有较大差别，从而降低了评估结果的保真性

> 这个问题没有完美的解决方案，常见的是将2/3~4/5的样本用作训练，剩余样本用作测试

#### 2.2.2 交叉验证法

先将数据集D划分为k个大小相似的互斥子集，即
$$
D=D_1∪D_2∪....∪D_k\\
D_i∩D_j=\empty (i\ne j)
$$
每个子集都尽可能保证数据分布的一致性，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而进行k次训练和测试，最终返回k个测试结果的均值

通常，把交叉验证法称为"k折交叉验证"(k-fold cross validation)

> 与留出法相同，这k个子集同样存在多种划分方式，为减少因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终评估的结果是这p次k这交叉验证结果的均值



**留一法 Leave-One-Out**

数据集D中包含m个样本，若令交叉验证法的k=m，则得到交叉验证法的一个特例，留一法

留一法使用的训练集与初始数据集只少了一个样本，这就使得在绝大多数情况下，留一法被实际评估的模型与与其评估的用D训练出的模型很相似



#### 2.2.3 自助法 bootstrapping

自主法以自助采样法(bootstrap sampling)为基础，给定包含m个样本的数据集D，我们对它进行采样产生数据集D'，每次随机从D中挑选一个标本，将其拷贝放入D'，然后再将该标本放回初始数据集D中，使得该标本在下次采样时仍有可能被踩到，重复这个过程m次后，我们得到包含m个样本的数据集D'

样本在m次采样中均不被采样到的概率为$(1-\frac1m)^m$，取极限
$$
\lim_{m\to \infin}(1-\frac1m)\to \frac 1e =0.368
$$
初始数据集中约有36.8的样本未出现在采样数据集D'中，于是我们可将D'用作训练集，D\D'用作测试机

这样的测试结果，也叫做"包外估计"(out-of-bag estimate)

**优点**

自助法适用于数据集较小，难以有效划分训练/测试集时很有效，对集成学习有很大好处

**缺点**

自助法产生的数据集改变了初始数据集的分布，这回引入估计偏差

> 在初始数据量足够时，留出法和交叉验证法更常用一些



#### 2.2.4 调参和最终模型

大多数学习算法都有些参数(parameter)需要设定，参数配置不同，学得模型的性能往往有显著差别,进行模型评估与选择时，除了要对适用学习算法进行选择，还需对算法参数进行设定，这就是通常所说的"参数调节"，简称"**调参**"(parameter tuning)

调参与算法选择没有什么本质区别，对每种参数配置都训练出模型，然后把最好的模型参数作为结果

但有一点需要注意：**很多学习算法的参数是实数范围内取值的**

现实中常用的做法是对每个参数选定一个范围和变化步长，从候选值中产生选定值，这样选定的参数往往不是最优值，**这时计算开销和性能估计之间进行折中的结果**

> 即使这样，实际训练中，计算开销也非常大



给定包含m个样本的数据集D，在模型评估与选择过程中需要留出一部分数据进行评估测试，只使用了一部分数据训练模型，因此在训练完成之后，我们选定学习算法和参数配置时，需要用数据集D重新训练模型，这个模型在训练过程中使用所有m个样本，这才是我们最终提交给用户的**最终模型**



> 学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，在模型评估与选择中用于评估测试的数据集常称为"**验证集**"(validation set)



### 2.3 性能度量

对学习器泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，即"**性能度量**"(performance measure)

> 性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往导致不同的评判结果，这意味着模型的"好坏是相对的"，模型的好坏不但取决于算法和数据，还取决于任务需求

给定样例集D=$\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$,其中$y_i$就是$x_i$的真实标记，要评估学习器f的性能，就要把学习器预测结果f(x)与真实标记y进行比较

回归任务最常用的性能度量是"均方误差"(mean squared error)
$$
E(f;D)=\frac 1m \sum_{i=1}^m (f(x_i)-y_i)^2
$$
更一般的,对于数据分布D和概率密度函数p(·)，均方误差可描述为
$$
E(f;D)=\int_{x-D} (f(x)-y)^2p(x)dx
$$

#### 2.3.1 错误率与精度

错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例，对样例集D，分类错误率定义为
$$
E(f;D)=\frac 1m \sum_{i=1}^m Ⅱ(f(x_i)\ne y_i)
$$
精度定义为
$$
acc(f;D)=\frac 1m \sum_{i=1}^m Ⅱ(f(x_i)= y_i)
$$
显然
$$
acc(f;D)=1-E(f;D)
$$
更一般的,对于数据分布D和概率密度函数p(·),错误率和精度可以分别描述为
$$
E(f;D)=\int_{x-D} Ⅱ(f(x_i)\ne y_i)p(x)dx
$$

$$
acc(f;D)==\int_{x-D}  Ⅱ(f(x_i)= y_i)p(x)dx
$$

#### 2.3.2 查准率、查全率与 Fl

对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例，假正例，真反例，假反例四种情形，令TP,FP,TN,FN分别表示对应的样例数，显然有TP+FP+TN+FN=样例总数，分类结果的"**混淆矩阵**"(confusion matrix)如下所示

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.png)

查准率P与查全率R分别定义为
$$
P=\frac{TP}{TP+FP}\\
R=\frac{TP}{TP+FN}
$$
查准率和查全率是一对矛盾的度量，查准率高时，查全率往往较低，查全率高时，查准率往往较低



在很多情形下,我们可根据学习器的预测结果对样例进行排序,排在前面的是学习器认为“最可能”是正例的样本,排在最后的则是学习器认为“最不可能”是正例的样本.按此顺序逐个把样本作为正例进行预测,则每次可以计算出当前的查全率、查准率.以查准率为纵轴、查全率为横轴作图,就得到查准率-查全率曲线,简称“P-R曲线”,显示该曲线的图称为“P-R图”.

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/P-R%E6%9B%B2%E7%BA%BF%E4%B8%8E%E5%B9%B3%E8%A1%A1%E7%82%B9%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

若一个学习器的P-R曲线被另一个学习器的曲线完全包住.则可断言后者的心梗呢优于前者，图中学习器A的性能优于学习器C，但是学习器A和B的性能难以比较

如果想要比较A和B的性能，一个合理的判据时比较P-R曲线下面积的大小，这一定程度下表征了学习器在查准率和查全率上去的双高的比例，但这个值不太容易估算

"**平衡点**"(Break-Event Point,BEP) 是一个总和考虑查准率，查全率的性能度量，它是查准率=查全率时的取值

> 比如：曲线A的BEP是0.8 曲线B的平衡点是0.73 可以认为学习器A优于学习器B



BEP过于简化，F1度量是更常用的
$$
F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}
$$

> F1是基于查准率和查全率的调和平均定义的
> $$
> \frac{1}{F1}=\frac12(\frac1P+\frac1R)
> $$

F1度量的一般形式，$F_{\beta}$，能让我们表达出对查准率和查全率的不同偏好
$$
F_{\beta}=\frac{(1+\beta^2)\times P \times R}{(\beta^2\times P)+R}
$$

> 公式中，β>0度量了查全率对查准率的相对重要性. β=1时，公式退化为F1，β>1时，查全率有更大影响，β<1时，查准率有更大影响



很多时候我们有多个二分类混淆矩阵，例如进行多次训练/测试，每次得到一个混淆矩阵，或是在多个数据集上进行训练/测试，希望估计算法的"全局"性能，甚或是进行多分类任务，没两两类别的组合都对应一个混淆矩阵...

很多时候，我们都希望在n个二分类混淆矩阵上综合考察查准率和查全率



一种直接的做法：直接在各个混淆矩阵上计算出查准率和查全率，记为(P1,R1),(P2,R2),...,(Pn,Rn)，在计算平均值，这样就得到了"宏查准率"，"宏查全率"和"宏F1"
$$
macro-P=\frac1n\sum_{i=1}^{n} P_{i}\\
macro-R=\frac1n\sum_{i=1}^{n} R_{i}\\
macro-F1=\frac{2\times macro-P\times macro-R}{macro-P+macro-R}
$$
也可以先对各混淆矩阵的对应元素进行平均，得到TP,NP,TN,FN的平均值，记为$\bar{TP},\bar{FP},\bar{TN},\bar{FN}$,再基于这些平均值计算出"微查准率"，"微查全率","微F1"
$$
micro-P=\frac{\bar{TP}}{\bar{TP}+\bar{FP}}\\
micro-R=\frac{\bar{TP}}{\bar{TP}+\bar{FN}}\\
micro-F1=\frac{2\times micro-P\times micro-R}{micro-P+micro-R}
$$

#### 2.3.3 ROC与AUC

很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值和一个分类阈值进行比较，若大于阈值则分为正类，否则为反类。这个实值或概率预测结果的好坏，直接决定了学习器的泛化能力。

根据这个实值或概率预测结果，我们可将测试样本进行排序,最可能是正例的排在最前面，最不可能是正例的排在最后面。这样分类过程就相当于在这个排序中以某个"**截断点**"(cut point)将样本分为两部分，前一部分判作正例，后一部分则判作反例



可根据任务需求来采用不同的截断点

>若更重视查准率，可在排序中靠前的位置进行截断，若更重视查全率，则可在排序中靠后的位置进行截断

排序本身质量的好坏，体现了综合考虑学习器在不同任务下的"期望泛化性能"的好坏或"一般情况下"泛化性能的好坏，ROC曲线是从这个角度触发来研究学习器泛化性能的有力工具



**ROC曲线**

全程是受试者工作特征(Receiver Operating Characteristic)曲线

根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得出了"ROC曲线"

ROC曲线的纵轴是"**真正例率**(True Positive Rate,简称TPR)"，横轴是"**假正例率**"(False Positive Rate,简称FPR)
$$
TPR=\frac{TP}{TP+FN}\\
FPR=\frac{FP}{TN+FP}
$$
![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ROC%E6%9B%B2%E7%BA%BF%E5%92%8CAUC%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

如图2.4(a)所示，对角线对应于"随机猜测模型"，点(0,1)则对应于将所有正例排在所有反例之前的"理想模型"

现实任务中，通常是利用有限个测试样例来绘制ROC图，此时仅能获得有限个(真正例率，假正例率)坐标对，只能绘制出如图2.4(b)所示的近似ROC曲线



在进行学习器的比较时，与P-R图相似，若一个学习器的ROC曲线被另一个学习器的ROC曲线完全包住，则断言后者的性能优于前者，若两个学习器的ROC曲线发生交叉，则需要ROC曲线下的面积，即AUC(Area Under ROC Curve)来做为评判标准

假定ROC曲线是由坐标为{(x1,y1),...,(xm,ym)}的点按序连接而形成(x1=0,xm=1)，AUC可估算为
$$
AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-{x_i})·(y_i+y_{i+1})
$$


形式化地看，AUC考虑的是样本预测地排序质量，因此它与排序误差有紧密联系，给定$m^+$个正例,$m^-$个反例，令$D^+,D^-$分别表示正、反例集合，则排序"**损失**"(loss)定义为
$$
l_{rank}=\frac{1}{m^+m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}(Ⅱ(f(x^+)<f(x^-)+\frac{1}{2}Ⅱ(f(x^+)=f(x^-)))
$$
即考虑每一对正、反例,若正例的预测值小于反例,则记一个"罚分",若相等,则记 0.5 个"罚分"容易看出,$l_{rank}$对应的是ROC曲线之上的面积 
$$
AUC=1-l_{rank}
$$

#### 2.3.4 代价敏感错误率与代价曲线

为权衡不同类型错误所造成的不同损失，可为错误赋予"**非均等代价**"(unequal cost)

二分类任务为例，我们可以根据任务的领域知识设定一个"代价矩阵"(cost matrix)

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%BB%A3%E4%BB%B7%E7%9F%A9%E9%98%B5.png)

其中$cost_{ij}$表示将第i类样本预测为第j类样本的代价

> 一般来说 $cost_{ii}=0$ 若将第零类判别为第一类的损失大于将第一类判别为第零类，则$cost_{01}>cost_{10}$
>
> 此外，重要的是代价比值而非绝对值



回顾前面介绍的一些性能度量可以看出，它们大都隐式地假设了均等代价

在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是最小化"**总体代价**"(total cost)

将表2.2中的第0类作为正类，第1类作为反类,$D^+和D^-$作为样例集D的正例子集和反例子集，则"**代价敏感**"(cost-sensitive)为
$$
E(f;D;cost)=\frac{1}{m}(\sum_{x_i\in D^+}Ⅱ(f(x_i)\ne y_i)\times cost_{01}+\sum_{x_i\in D^-}Ⅱ(f(x_i)\ne y_i)\times cost_{10})
$$
在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而"**代价曲线**"(cost curve)则可达到该目的。

代价曲线图的横轴是取值为[0,1]的正例概率代价
$$
P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}
$$
其中p是样例为正例的概率；纵轴是取值为[0,1]的归一化代价
$$
cost_{norm}=\frac{FNR\times p \times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}
$$


![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E4%BB%B7%E6%9B%B2%E7%BA%BF%E4%B8%8E%E6%9C%9F%E6%9C%9B%E6%80%BB%E4%BD%93%E4%BB%A3%E4%BB%B7.png)

代价曲线的绘制很简单：ROC曲线上没一点对应了代价平面上的一条线段，设ROC曲线上点的坐标为(TPR,FPR),则可相应计算出FNR，然后再代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，线段下的面积表示了该条件下的期望总体代价，如此将ROC曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，为主的面积即为所有条件下学习器的期望总体代价



### 2.4 比较检验

机器学习中性能比较这件事要比大家想象的复杂得多，这里面涉及几个重要的因素

1. 我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试集上的性能，二者的对比结果可能未必相同
2. 测试集上的性能与测试集本身的选择有很大关系，且不论不同大小的测试集会得到不同的结果，即便使用相同大小的测试集，若包含的测试样例不同，测试结果也会有不同的结果
3. 很多机器学习算法都有一定的随机性，即便使用相同的参数设置在同一个测试集上运行多次，其结果也会有不同

统计**假设检验**(hypothesis test)为我们进行学习器性能比较提供了重要依据，基于假设检验，我们可以推断出，若在测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大

> 本节默认以错误率为性能度量，用$\epsilon$表示



#### 2.4.1 假设检验

假设检验中的假设是对学习器泛化错误率分布的某种判断或猜想，例如$\epsilon=\epsilon_0$

现实任务中我们并不知道学习器的泛化错误率，只能获知其测试错误率$\hat{\epsilon}$，可根据测试错误率估推出泛化错误率的分布

> 直观上，泛化错误率和测试错误率接近的可能性比较大



在包含m个样本的测试集上，泛化错误率为ε的学习器被测得错误率为$\hat {\epsilon}$的概率为
$$
P(\hat{\epsilon},\epsilon)=C_m^{\hat{\epsilon}\times m}\epsilon^{\hat{\epsilon}\times m }(1-\epsilon)^{m-\hat{\epsilon}\times m}
$$
将次概率对ε求偏导得0，可知概率在$\epsilon =\hat{\epsilon}$是最大，$|\epsilon-\hat{\epsilon}|$增大，概率减小，符合二项分布

如果ε=0.3,则10个样本中，测得3个呗误分类得概率最大

我们可以使用"**二项检验**"(binomial test)来对"ε$\le0.3$"这样的假设来进行检验

考虑假设"$\epsilon\le \epsilon_0$"，则在1-α的概率能所能观测到的最大错误率如下式计算
$$
\bar \epsilon=max \in s.t. \sum_{i=\epsilon \times m +1}^{m} C_m^i \epsilon^i(1-\epsilon)^{m-i}<\alpha
$$
此时若测试错误率$\hat\epsilon$小于临界值,则根据二项检验可得出结论：在$\alpha$的显著度下，假设"$\epsilon\le \epsilon_0$"不能被拒绝，即能在1-α的置信度认为，学习器的泛化错误率不大于$\epsilon_0$，否则该假设可以拒绝，即在$\alpha$的显著度下可认为学习器的泛化错误率大于$\epsilon_0$



很多时候我们并非仅做一次留出法估计，而是通过多次留出法或是交叉验证法等进行多次训练/测试，这样会得到多个测试错误率，此时可使用"t检验".

假定我们的到了k个测试错误率$\hat \epsilon_1,\hat \epsilon_2,...,\hat \epsilon_k,$,则平均实验误差μ和方差$σ^2$为
$$
μ=\frac 1k \sum _{i=1}^k \hat \epsilon_i\\
\sigma^2=\frac1 {k-1} \sum^k_{i=1}(\hat \epsilon _i-\mu)^2
$$
考虑到这k个测试错误率可以看作泛化错误率$\epsilon_0$的独立采样，则变量
$$
\tau_t=\frac{\sqrt{k}(\mu-\epsilon_0)}{\sigma}
$$
服从自由度为k-1的t分布

对于假设"μ=$ε_0$"和显著度α，我们可以计算出当测试错误率均值在$\epsilon_0$时，在1-α概率内能观测到的最大错误率，即临界值，这里考虑双边假设



#### 2.4.2 交叉验证t检验 

对两个学习器 A 和 B ，若我们使用 k 折交叉验证法得到的测试错误率分别为$\epsilon_1^A,\epsilon_2^A,...,\epsilon_K^A$和$\epsilon_1^B,\epsilon_2^B,...,\epsilon_K^B$，其中$\epsilon_i^A$和$\epsilon_i^B$是在相同的第 k折训练/测试集上得到的结果  

可用 k 折交叉验证"成对 t 检验" (paired t-tests)来进行比较检验  

**基本思想**

若两个学习器的性能相同，则它们使用相同的训练/测试集得到的测试错误率应相同，即 
$$
\epsilon_i^A=\epsilon_i^B
$$
**检验步骤**

1. 对每对结果求差

$$
\Delta_i=\epsilon_i^A-\epsilon_i^B
$$

2. 根据差值来对“学习器A与学习器B性能相同”这个假设做t检验，计算出差值的均值μ和方差$σ^2$

在显著度α下，若变量
$$
\tau_t=|\frac{\sqrt{k}\mu}{\sigma}|
$$
小于临界值$t_{\alpha/2,k-1}$，则假设不能拒绝，认为==两个学习器性能没有显著差别==

否则,认为==两个学习器的性能有显著差别，且平均错误率小的那个学习器性能较优==

---

==**以下为本节内容，但并未在课(PPT)中提及**==

> 欲进行有效的假设检验，一个重要前提是测试错误率均为泛化错误率的独立采样  

由于样本有限，在使用交叉验证等实验评估方法时，不同轮次的训练集会有一定程度的重叠，使得测试错误率实际上并不独立，会导致过高估计的假设成立的概率

为了缓解这一问题，可采用"5x2交叉验证"



5x2交叉验证，是做5次2折交叉验证，在每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复



对于学习器A和B。第i次2折交叉验证将产生两队测试错误率，我们对它们分别求差，得到第1折上的差值$\Delta_i^1$和第2折上的差值$\Delta_i^2$

为缓解测试错误率的非独立性，我们仅计算第一次2折交叉验证的两个结果的平均值
$$
\mu=0.5(\Delta_i^1+\Delta_i^2)
$$
但对每次2折实验的结果都计算出其方差
$$
\sigma_i^2=(\Delta_i^1-\frac{(\Delta_i^1+\Delta_i^2)}{2})^2+(\Delta_i^2-\frac{(\Delta_i^1+\Delta_i^2)}{2})^2
$$
变量
$$
\tau_t=\frac{\mu}{\sqrt{0.2\sum_{i=1}^5}\sigma^2}
$$
服从自由度为5的t分布，其双边检验的临界值$\tau_{\alpha/2,5}$



#### 2.4.3 McNemar检验

**==本节内容未在课(PPT)中提及==**

对于二分类问题，使用留出法不仅可估计出学习器A和B的测试错误率，还可以获得量学习器分类结果的差别，即两者都正确，都错误，一个正确一个错误的样本数

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%94%E5%88%97%E8%A1%A8.png)

若我们做的假设是两学习器性能相同，则有$e_{01}=e_{10}$，那么变量$|e_{01}-e_{10}|$应当服从正态分布，且均值为1，方差为$e_{01}+e_{10}$，因此变量
$$
\tau_{\chi^2}=\frac{(|e_{01}-e_{10}|-1)^2}{e_{01}+e_{10}}
$$
服从自由度为1的$\chi^2$分布，即标准正态分布变量的平方

给定显著度 α，当以上变量恒小于临界值$\chi^2_α$时，不能拒绝假设，即认为两学习器的性能没有显著差别;否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习器性能较优  



#### 2.4.4 Friedman检验与Nemenyi后续检验

**==本节内容未在课(PPT)中提及==**

上面几节提到的交叉验证t检验和McNemar检验都是在一个数据集上比较两个算法的性能，而很多时候，我们会在一组数据上对多个算法进行比较

这时，一种做法是在每个数据集上分别列出两两比较的结果，而在两两比较时可使用前述方法

另一个种方法更为直接，就是本节提到的 **基于算法排序的Friedman检验**



假定我们用$D_1,D_2,D_3,D_4$四个数据集对算法A,B,C进行比较

步骤如下：

1. 使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏排序，并赋序列值1，2，...；若算法的测试性能相同，则平分序列值,通过每一列的序值求平均，得到平均序值

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83%E5%BA%8F%E6%8C%87%E8%A1%A8.png)

2. 使用Friedman检验来判断这些算法性能是否相同，若相同，则它们的平均序值应该相同

   假定我们在N哥数据集上比较k个算法，令$r_i$表示第i个算法的平均序值(为了简化讨论，暂不考虑平分序值得情况)，则$r_i$服从正态分布，其均值和方差分别为(k+1)/2和$(k^2-1)/12$，变量
   $$
   \tau_{\chi^2}=\frac{k-1}k·\frac{12N}{k^2-1}\sum_{i=1}^k(r_i-\frac{k+1}{2})^2\\=\frac{12N}{k(k+1)}(\sum_{i=1^k}r_i^2-\frac{k(k+1)^2}{4})
   $$
   在k和N都较大时，服从自由度为k-1的$\chi^2$分布

​		上述的"原始Friedman检验"太过于保守，现在通常使用变量
$$
\tau_F=\frac{(N-1)\tau_{\chi^2}}{N(k-1)-\tau_{\chi^2}}
$$
​		其中$\tau_{\chi^2}$由上式得到，$\tau_F$服从自由度为k-1和(k-1)(N-1)的F分布

3. 若"所有算法的性能相同"这个假设被拒绝，则说明算法的性能显著不同，需要"后续检验"(post-hoc test)来进一步区分各算法，常用的由Nemenyi后续检验

   Nemenyi检验计算出平均序值差别得临界值域
   $$
   CD=q_{\alpha}\sqrt{\frac{k(k+1)}{6N}}
   $$
   若两个算法的平均序值之差超出了临界值域CD，则以置信度拒绝"两个算法性能相同"这一假设



### 2.5 偏差与方差

除了通过实验估计泛化学习算法的性能，我们还希望了解它为什么具有这样的性能.

**"偏差-方差分解"**(bias-variance decomposition)是解释学习算法泛化性能的一种重要工具

偏差-方差分解试图对学习算法的期望泛化率进行拆解

一个算法在不同训练集上学得的结果很可能不同，即使这些训练集来自同一个分布

对于测试样本x，令$y_D$为x在数据集中的标记，y为x的真实标记，f(x;D)为训练集D上学得模型f在x上的预测输出

以回归任务为例，学习算法的期望值为
$$
\bar{f}(x)=E_D[f(x;D)]
$$
使用样本数相同的不同训练集产生的方差为
$$
var(x)=E_D[(f(x;D)-\bar f(x))^2]
$$
噪声为
$$
\epsilon^2=E_D[(y_D-y)^2]
$$
期望输出与真实标记的差别称为偏差(bias)
$$
bias^2(x)=(\bar f(x)-y)^2
$$
便于讨论，假定噪声为0，通过简单地多项式展开合并，可对算法的期望泛化误差进行分解
$$
E(f;D)=bias^2(x)+var(x)+\epsilon^2
$$
泛化误差可分解为偏差、方差、噪声之和

- 偏差度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力

- 方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响
- 噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度

偏差一方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的.给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小.  



**偏差-方差窘境**(bias-variance dilemma)

给定学习任务，假定我们能控制学习算法的训练程度，则在训练不足时,学习器的拟合能力不够强，训练数据的扰动不足以便学习器产生显著变化，此时偏差主导了泛化错误率;随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率;在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合.  

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE%E3%80%81%E6%96%B9%E5%B7%AE%E7%9A%84%E5%85%B3%E7%B3%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png)



## 第七章 贝叶斯分类器

*按照授课顺序，第二章过后学习第七章相关内容

### 7.0 数学知识补充

#### 7.0.1 贝叶斯公式

贝叶斯公式是贝叶斯决策理论的基础，其一般形式为
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
其中,P(A|B)是**后验概率**，即事件B发生的情况下，事件A发生的概率

P(B|A)是**条件概率**，即在事件A发生的情况下，事件B发生的概率

P(A)是事件A的**先验概率**，即没有其他额外信息的情况下，事件A发生的概率

P(B)是事件B的**先验概率**或边缘概率

对公式进行变型
$$
P(c_i|x)=\frac{p(x|c_i)p(c_i)}{p(x)}
$$


#### 7.0.2 贝叶斯决策论基本原理

贝叶斯决策理论通过计算后验概率，为分类问题提供了直观且有效的解决方案，分类时选择后验概率最大的分类

### 7.1 贝叶斯决策论

**贝叶斯决策论**(Bayesian decision theory)是概率框架下实施决策的基本方法

对分类任务来说，在所有相关概率都已知的理想情况下，贝叶斯决策论考虑如何基于这些概率和判误损失来选择最优的类别标记



假设有N种可能的标记类别，即$\gamma={c_1,c_2,...,c_N}$，$\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失。基于后验概率$P(c_i|x)$可获得将样本分类为$c_i$所产生的期望损失(expected loss)，即在样本x上的"条件风险"(conditional risk)
$$
R(c_i|x)=\sum_{j=1}^N \lambda_{ij}P(c_j|x)
$$

> 决策论中将“期望损失”称为风险

我们的任务是寻找一个判定准则$h:\chi \mapsto \gamma$以最小化总体风险
$$
R(h)=\mathbb{E}[R(h(x)|x)]
$$
显然，对每个样本x，若h能最小化条件风险$R(h(x)|x)$,则总体风险R(h)也将被最小化，这就产生了**贝叶斯判定准则**

为最小化总体风险，只需将每个样本上选择那个能使条件风险R(c|x)最小的类别标记，即
$$
h^*(x)={arg~min}_{c\in \gamma}R(c|x)
$$
此时，$h^*$称为**贝叶斯最优分类器**(Bayes optimal classifier)，与之对应的总体风险R($h^*$)被称为**贝叶斯风险**(Bayes risk)

1-$R(h^*)$反映了分类器所能达到的最好性能

具体来说，若目标是最小化分类错误率，则误判损失$\lambda_{ij}$可写为
$$
\lambda_{ij}=\begin{cases} {0},{if~~i=j}\\1,~~{otherwise}\end{cases}
$$
此时条件风险
$$
R(c|x)=1-P(c|x)
$$
于是，最小化分类错误率的贝叶斯最优分类器为
$$
h^*(x)=arg max_{c\in y} P(c|x)
$$
即对每个样本x，选择能使后验概率P(c|x)最大的类别标记

不难看出，欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概率p(c|x)。然而现实任务中，这通常难以获得。从这个角度来看，机器学习所要实现的使基于有限的训练样本，尽可能地准确估算出后验概率P(c|x),大体来说有两种主要策略:

1. 给定x，可通过直接建模P(c|x)来预测c，得到"判别式模型"(discriminative models)
2. 也可以先对联合概率分布P(x,c)建模，然后再由此获得P(c|x)，这样得到的是"生成式模型"(generative models)

对于生成式模型，必然考虑
$$
P(c|x)=\frac{P(x,c)}{P(x)}
$$
基于贝叶斯定理，p(c|x)可写为
$$
P(c|x)=\frac{P(c)P(x|c)}{P(x)}
$$
P(x)是用于归一化的"证据"因子，对于给定样本x，证据因子P(x)与类标记无关，所以估计P(c|x)的问题就转化为如何基于训练数据估计先验概率P(c)和似然P(x|c)

类先验概率P(c)根据大数定律，当训练集包含重组的独立同分布样本时，可通过各类样本出现的频率进行估计

对类条件概率P(x|c)来收，由于它涉及关于x所有数学的联合概率，直接根据样本出现的频率来将会遇到严重的困难(见下面解释)，直接使用频率来估计P(x|c)显然不可行

> 假设样本的d个属性都是二值的，则样本空间有$2^d$种可能得取值，在现实中，这个值往往远大于训练样本数m，也就是说，很多样本取值在训练集种根本没有出现

### 7.2 极大似然估计

估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计

具体来说，记关于类别c的类条件概率为P(x|c)，假设P(x|c)具有确定的形式并且被参数向量$\theta_c$唯一确定，则我们的任务就是利用训练集D估计参数$\theta_c$

为明确起见，我们将P(x|c)记为P(x|$\theta_c$)

**极大似然估计**，是根据数据采样来估计概率分布参数的经典方法

令$D_c$表示训练集D种第c类样本组成的集合，假设这些样本是独立同分布的，则参数$\theta_c$对于数据集$D_c$的似然是
$$
P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)
$$
对$\theta_c$进行极大似然估计，就是取寻找能最大化似然P($D_c|\theta_c$)的参数值$\hat\theta_c$

连乘操作容易造成下溢，通常使用对数似然(log-likeihood)
$$
LL(\theta_c)=logP(D_c|\theta_c)\\=\sum_{x\in D_c}logP(x|\theta_c)
$$
此时参数$\theta_c$的极大似然估计值$\hat{\theta_c}$为
$$
\hat{\theta_c}=arg~max_{\theta_c} LL(\theta_c)
$$


### 7.3 朴素贝叶斯分类器

基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计

为了避开这个障碍，朴素贝叶斯分类器使用了"属性条件独立性假设"，对于已知类别，假设所有属性相互独立，则
$$
P(c|x)=\frac{P(c)P(x|c)}{p(x)}=\frac{P(c)}{P(x)}\prod_{i=1}^{d}P(x_i|c)
$$
由于对所有类别来说，P(x)相同，因此基于上式的贝叶斯判定准则又
$$
h_{nb}(x)=arg~max_{c \in \gamma}P(c)\prod_{i=1}^d P(x_i|c)
$$
显然，朴素贝叶斯分类器的训练过程就是基于训练集来估计先验概率P(c),并为每个属性估计条件概率P($x_i$|c)

先验概率容易估计
$$
P(c)=\frac{|D_c|}{|D|}
$$
对于离散属性而言，条件概率P($x_i|c$)可估计为
$$
P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}
$$
对于连续属性，可考虑概率密度函数



**拉普拉斯修正**

若某个属性再训练集种没有与某个类同时出现过，则直接基于上式进行概率估计，再进行判别，会出现问题

此时计算概率时，就要使用拉普拉斯修正
$$
\hat P (c)=\frac{|D_c+1|}{|D|+N}\\
\hat P (x_i|c)=\frac{|D_{c,x_i}+1|}{|D_c|+N_i}\\
$$
其中，N表示训练集D种可能的类别数，$N_i$表示第i个属性可能的取值



### 7.4 半朴素贝叶斯分类器

在现实任务中,朴素贝叶斯公式采用的属性条件独立性假设往往很难成立



**半朴素贝叶斯分类器**

适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系



**独依赖估计**(One-Dependent Estimator,ODE)

半朴素贝叶斯分类器最常用的一种策略，假设每个属性在类别之外最多仅依赖于一个其他属性
$$
P(c|x) \propto P(c) \prod_{i=1}{d}P(x_i|c,pa_i)
$$
其中$pa_i$为属性$x_i$所依赖的属性，称为$x_i$的父属性.此时，对于每个属性$x_i$，若父属性$pa_i$已知，则可采用类似于
$$
\hat P (x_i|c)=\frac{|D_{c,x_i}+1|}{|D_c|+N_i}\\
$$
的方法来估计概率值P($x_i|c,pa_i$)



于是，问题转化为如何确定每个属性的父属性

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%8E%E4%B8%A4%E7%A7%8D%E5%8D%8A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E6%89%80%E8%80%83%E8%99%91%E7%9A%84%E5%B1%9E%E6%80%A7%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB.png)

最直接的做法是假设所有属性都依赖于同一个属性，称为**超父(super-parent)**

然后通过交叉验证等模型选择方法来确定超父属性，由此形成了SPODE(super-parent ODE)方法



**TAN(Tree Augmented naive Bayes)**则是在最大带权生成树算法的基础上，通过以下步骤将属性间的依赖关系简化为如7.1(c)所示的属性结构:

1. 计算任意两个属性之间的条件相互信息

$$
I(x_i,x_j|y)=\sum_{x_i,x_j;c\in \gamma}P(x_i,x_j|c)log\frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}
$$

2. 以属性为节点构建完全图，任意两个节点之间边的权重设为I($x_i,x_j|y$)

3. 构建此完全图的最大带权生成树，挑选根变量，将边置为有向
4. 加入类别节点y,增加从y到每个属性的有向边



**AODE(Averaged One-Dependent Estimator)**是一种基于集成学习机制，更为强大的独依赖分类器,AODE尝试将每个属性作为超父来构建SPODE，然后将那些具有足够训练数据支撑的SPODE集成起来作为最终结果
$$
P(c|x) \propto {\sum_{i=1}^{d}}_{|D_{x_i}|\ge m'}P(c,x_i)\prod_{j=1}^dP(x_j|c,x_i)
$$
其中$D_{x_i}$是在第i个属性上取值为$x_i$的样本的集合，m'为阈值常数。AODE需估计P($c,x_i$)和P($x_j|c,x_i$)
$$
\hat P (c,x_i)=\frac{|D_{c,x_i}+1|}{|D|+N_i}\\
\hat P (x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,x_i}|+N_j}\\
$$
N_i 是第i个属性可能的取值数

$D_{c,x_i}$是类别为c且在第i个属性上取值为$x_i$的样本集合

$D_{c,x_i,x_j}$是类别为c且在第i和第j个属性上取值为$x_i$和$x_j$的样本集合



### 7.5 贝叶斯网

**贝叶斯网(Bayesian network)**

也叫信念网(belief network),借助有向无环图来刻画属性之间的依赖关系，并使用条件概率表来描述属性的联合概率分布

一个贝叶斯网B由结构G和参数$\Theta$两部分构成，即$B=<G,\Theta>$

网络结构G是一个有向无环图，每个节点对应一个属性，若两个属性由直接依赖关系，则它们由一条边连接起来

参数$\Theta$定量描述这种依赖关系，假设属性$x_i$在G中的父节点集为$\pi_i$，则$\Theta$包含了每个属性的条件概率表$\theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%A4%BA%E4%BE%8B.png)



#### 7.5.1 结构

**联合概率分布**

贝叶斯网假设每个属性与它的非后裔属性独立，于是B=$<G,\Theta>$将属性$x_1,x_2,...,x_d$的联合概率分布定义为
$$
P_B(x_1,x_2,...,x_d)=\prod_{i=1}^dP_B(x_i|\pi_i)=\prod_{i=1}^d\theta_{x_i|\pi_i}
$$
以图7.2为例，联合概率分布定义为
$$
P(x_1,x_2,...,x_5)=P(x_1)P(x_2)P(x_3|x_1)P(x_4|x_1,x_2)P(x_5|x_2)
$$
显然，$x_3,x_4$在给定$x_1$的取值时独立，$x_4,x_5$在给定$x_2$的取值时独立，分别简记为$x_3\perp x_4|x_1$和$x_4\perp x_5|x_2$

**贝叶斯网中三个变量之间的典型依赖关系**

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E4%B8%89%E4%B8%AA%E5%8F%98%E9%87%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B8%E5%9E%8B%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB.png)



同父结构中，给定父结点$x_1$的取值,则$x_3与x_4$条件独立

顺序结构中，给定x的取值，则y和z条件独立

V型结构，也叫做冲撞结构，给定子节点$x_4$的取值，$x_1和x_2$必不独立;但若$x_4$的取值完全位置，$x_1与x_2$却是相互独立的,记作$x_1 ⫫x_2$

> 在同父结构中，若$x_1$的取值未知，则$x_3和x_4$就不独立
>
> 在顺序结构中，x的取值未知，y和z也不独立



**有向分离(D-separation)**

为了分析有向图中变量间的条件独立性，我们可以使用"有向分离"将一个有向图转变为一个无向图:

1. 找出有向图中所有V型结构，在V型结构的两个父节点之间加上一条无向边
2. 将所有有向边改为无向边

由此产生的无向图称为**道德图**(moral graph)，令父节点相连的过程称为"**道德化**"(moralization)



基于道德图可以直观，迅速地找到变量之间的条件独立下。假定道德图中有变量x,y和变量集合$z={z_i}$，即从道德图中将变量集合z取出后，x和y属两个连通分支，则称x和y被z有向分离,$x\perp y|z$成立



#### 7.5.2 学习

若网络结构(即属性间的依赖关系)已知，则贝叶斯网的学习过程就是通过对样本"计数"，估计出每个结点的条件概率表即可.但在现实应用中，我们往往不知晓网格结构

贝叶斯网学习的首要任务就是根据训练集来找出结构最"恰当"的贝叶斯网

**评分搜索**

定义一个**评分函数**(score function),以此来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网

> 评分函数会引入我们希望获得什么样的贝叶斯网的归纳偏好



常见的评分函数通常基于信息论准则，将学习问题看作一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时的编码长度包括了描述模型自身所需要的字节长度和使用该模型描述数据所需的字节长度.

对贝叶斯学习来说，模型就是一个贝叶斯网，同时每个贝叶斯网描述了一个在训练数据上的概率分布，自有一套编码机制能使那些经常出现的样本有更短的编码.于是，我们应选择哪个综合编码长度最短的贝叶斯网，这就是"**最小描述长度**"(Minimal Description Length,MDL)准则



给定训练集$D={x_1,x_2,...,x_m}$，贝叶斯网B=$<G,\Theta>$在D上的评分函数可写为
$$
s(B|D)=f(\theta)|B|-LL(B|D)
$$
其中,|B|是贝叶斯网的参数个数，f($\theta$)表示描述每个参数$\theta$所需的字节数，而
$$
LL(B|D)=\sum_{i=1}^m logP_B(x_i)
$$
是贝叶斯网的对数似然

> 式的第一项计算编码贝叶斯网B所需要的字节数，第二项计算B所对应的概率分布$P_B$需要多少字节来描述D



**AIC(Akaike Information Criterion)**

当$f(\theta)=1$，即每个参数都用一个字节描述，则得到AIC评分函数
$$
AIC(B|D)=|B|-LL(B|D)
$$
**BIC(Bayesian Infromantion Criterion)**

当$f(\theta)=\frac12log~m$，则得到BIC评分函数
$$
BIC(B|D)=\frac{log~m}{2}|B|-LL(B|D)
$$


若f($\theta$)=0，即不进行对网络进行编码的长度，则评分函数退化为负对数似然，学习任务退化为极大似然估计



若贝叶斯网的网络结构G固定，则评分函数前一项为常数，此时，最小化s(B|D)等价于对参数$\Theta$的极大似然估计,参数$\theta_{x_i|\pi_i}$能直接在训练数据D上通过经验估计获得
$$
\theta_{x_i|\pi_i}=\hat P_D({x_i|\pi_i})
$$
其中$\hat P_D(·)$是D上的经验分布，因此，为了最小化评分函数s(B|D)，只需要对网络结构进行搜索，而候选结构的最优参数可直接在训练集上计算得到



从所有可能得网络结构空间中搜索最优贝叶斯网结构是一个NP难问题

两种常用策略用于在有限时间内求得近似解

1. 贪心，从某个网络结构出发，每次调整一条边，直到评分函数值不再降为止
2. 通过给网络结构施加约束来削减搜索空间，例如将网络结构限定为树形结构



#### 7.5.3 推断

贝叶斯网训练好后就能用来回答"**查询**"(query)

通过已知变量观测值来推断查询变量的过程称为"**推断**"(inference)

已知变量观测值称为"**证据**"(evidence)



根据贝叶斯网定义的联合概率分布来精确计算后验概率是最精确的，但这以及被证明是NP-hard的，我们只能寄希望于近似推断,通过降低精度要求，在有限时间内求得近似解



**吉布斯采样**(Gibbs sampling)

![](image/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%89%E5%B8%83%E6%96%AF%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95.png)

令Q=${Q_1,Q_2,...,Q_n}$表示待查询变量，E={$E_1,E_2,...,E_k$}为证据变量，已知其取值为       e={$e_1,e_2,...,e_k$}.目的是计算后验概率P(Q=q|E=e)，其中q={$q_1,q_2,...,q_n$}是待查询变量的一组取值



吉布斯采样算法执行流程：

1. 随机产生一个与证据E=e一致的样本$q^0$作为初始点
2. 在第t次采样中，假设$q^t=q^{t-1}$，然后对非证据变量逐个进行采样改变其取值，采样概率根据贝叶斯网B和其他变量的当前取值计算获得
3. 经过T次采样得到的与q一致的样本有$n_q$个，则可近似估算出后验概率

$$
P(Q=q|E=e) \approx \frac{n_q}{T}
$$

> 实质上，吉布斯采样实在贝叶斯网所有变量的联合状态空间与证据E=e一致的子空间中进行"随机漫步"
>
> 每一步仅依赖于前一步的状态，这是一个马尔科夫链(Markov chian)
>
> 马尔科夫链第t不得状态分布在$t\to \infin$时必收敛于一个平稳分布，这个分布对于吉布斯采样恰好是P(Q|E=e)

马尔科夫链通常需要很长的时间才能趋于平稳分布，吉布斯采样算法收敛速度较慢

贝叶斯网中不能存在极端概率0或1，否则无法保证马尔科夫链存在平稳分布，从而导致吉布斯采样给出错误的估计结果



### 7.6 EM算法

上面讨论中，训练样本的所有属性变量的值都假设为已被观测到，但在现实情况中，可能会存在“未观测”变量的情况

未观测变量的学名是“隐变量”（latent variable) 

令X表示已观测变量集，Z表示隐变量，$\Theta$表示模型参数，欲对$\Theta$做极大似然估计，则应最大化对数似然
$$
LL(\Theta|X,Z)=ln P(X,Z|\Theta)
$$
由于Z是隐变量，上式无法直接求解，我们可以通过对Z计算期望，来最大化已观测数据的对数"边际似然"
$$
LL(\Theta|X)=lnP(X|\Theta)=ln\sum_ZP(X,Z|\Theta)~~~(7.35)
$$
**EM(Expectation-Maximization)算法**

是常用的估计参数隐变量的利器，是一种迭代式的方法，其基本思想是：若参数$\Theta$已知，则可根据训练数据推断出最优隐变量Z的值(E步)；反之，若Z的值已知，则可方便地对参数$\Theta$做极大似然估计

以初始值$\Theta^0$为起点，对式(7.35)，可迭代执行以下步骤直收敛：

1. 基于$\Theta^t$推断隐变量Z的期望，记作$Z^t$
2. 基于已观测变量X和$Z^t$对参数$\Theta$做极大似然估计，记为$\Theta^{t+1}$



进而，我们不是取Z的期望，而是基于$\Theta^t$计算隐变量Z的概率分布P($Z|X,\Theta^t$),则EM的两个步骤是

1. 以当前参数$\Theta^t$推断隐变量分布P(Z|X,$\Theta^t$),并计算对数似然LL($\Theta$|X,Z)关于Z的期望

$$
Q(\Theta|\Theta^t)=\mathbb E_{Z|X,\Theta^t}LL(\Theta|X,Z)
$$

2. 寻找参数最大化期望似然

$$
\Theta^{t+1}=arg max_{\Theta}Q(\Theta|\Theta^t)
$$

